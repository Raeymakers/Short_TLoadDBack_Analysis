---
title: "ALL_TOGETHER"
author: "Sofie Raeymakers"
date: "7/6/2022"
output: html_document
---

---
title: "PVT_VAS-f_analysis"
author: "Sofie Raeymakers"
date: "5/3/2022"
output: html_document
---

```{r setup, include=FALSE}
rm(list = ls()) # Clear environment
cat("\014") # Clear console
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning = FALSE}
##### Set environment #####
library(tidyverse)
library(effects)
library(emmeans)
library(data.table)
library(dplyr)
library(lme4)
library(ggplot2)
library(MuMIn)
library(effsize)
library(reshape2)
library(cowplot)
library(car)
library(ggpubr)

# Get and declare functions
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source("C:/Users/ASUSTeK/OneDrive/Documenten/Github/Short_TLoadDBack/functions.R") # file in the same directory for functions so they're together
#Set working directory to the folder in which all CSV files are located
Dir = "C:/Users/ASUSTeK/OneDrive/Documenten/Github/Short_TLoadDBack/Data/"
setwd(Dir)

# save figures
if (!dir.exists("figures")){ # Create folder for storing the figures if it doesn't exist yet
  dir.create("figures")}
plotPrefix <- paste0(Dir,"figures/") # Prefix to easily store figures later
```

```{r message=FALSE, warning = FALSE}
##########################################
  ### PVT/VIGILANCE/RT ###
#########################################
# we want to see if PVT/vigilance is different in day 1 compared to day 2 and in HCl compared to LCl (Condition) before the test

#### DOWNLOAD + CLEAN DATA ####

#Download PVT data (this datafile is made in 'preprocessing')
data <- read.csv(paste0(Dir, "PVT.csv"), header = TRUE, sep = )
# mean 1/RT
data$RT <- 1/(data$RT/1000) #1/RT  ==> other result

## CREATE DATAFRAME  with the MeanRT per ID, Day, Condition
PVT <- as.data.frame(group_by(data, Test, Day, Condition, ID) %>%
  summarise(
    count = n(),
    Mean = mean(RT, na.rm = TRUE)
  ))
PVT <- PVT[!(PVT$Test==2),] # we will only look at before-test measures

# visualise RT's: from 0 to 10 seconds 
d<-melt(data.frame(RT=c(PVT$Mean))) # we melt to wide format
distribution_plot (d, 'Mean')
qqPlot(PVT$Mean) # clearly not a normal distribution: a big skew 

# make factors
PVT$Day <- factor(PVT$Day)
PVT$ID <- factor(PVT$ID)
PVT$Condition <- factor(PVT$Condition)+


### CHECKING ASSUMPTIONS ####
# Time x Condition 2-way ANOVA with interaction effect (what Borrogan did)
res.aov2 <- aov(Mean ~ Condition * Day, data= PVT)
summary(res.aov2)# no sign! this is good, means vigilance was same in all conditions

# HOMOGENEITY OF VARIANCE
plot(res.aov2, 1) # residuqls vs fits plot shows no evident relationship residuals and fitted values (means of groups)

# NORMALITY
aov_residuals <- residuals (object=res.aov2)
shapiro.test(x=aov_residuals) # no normality! 
PVT %>%
  group_by(Condition, Day) %>%
  shapiro_test(Mean) # no normal distribution!
#visualisation
plot(res.aov2, 2) #clearly not normal
ggqqplot(PVT, "Mean", ggtheme = theme_bw()) +
  facet_grid(Day ~ Condition)
ggqqplot(PVT, "Mean", ggtheme = theme_bw()) +
  facet_grid( ~Condition) #  very obviously NOT a normal distribution

# OUTLIERS
summary(PVT$Mean)
outliers <- boxplot(PVT$Mean, plot=FALSE)$out
# remove 
PVT<- PVT[-which(PVT$Mean %in% outliers),]
#visualise
d<-melt(data.frame(RT=c(PVT$Mean))) # we melt to wide format
distribution_plot (d, 'Mean') # much better
qqPlot(PVT$Mean) # much better


### ANALYSIS ###
#https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01171/full
#https://stats.stackexchange.com/questions/254361/modeling-reaction-time-with-glmer
# => glmer with inverse link: can handle RT that is not normally distributed
two_w <- glmer (Mean~Condition * Day  + (1|ID), data= PVT, family= inverse.gaussian(link="identity"))
emmeans1<- emmeans(two_w, pairwise ~ Condition * Day, adjust ="fdr", type = "response")
emmean_dataframe <- summary(emmeans1)$emmeans

Anova(two_w, type='III')
summary(emmeans1) ## Result the SAME for data with or without outliers (PVT & PVT2): because it is glmer
# but removing the outliers makes visualisations much more readable
#summary 
sum <- sum_2 (PVT, 'Day', 'Condition', 'Mean')
sum


### VISUALISATION ###
# boxplot 
bxp <- ggboxplot(
  PVT, x = "Day", y = "Mean",
  color = "Condition", palette = "jco")
bxp

## plot with error bars
pl <- plotty(PVT, emmean_dataframe, 'Day',  'Mean', 'Condition', 'emmean', 'Vigilance') 
  #   geom_segment(aes(x =0.9, y = max_y+max_y/15, xend = 1.1, yend = max_y+max_y/15), size= 1)+ # top line
  # annotate('text', x=1, y=max_y+max_y/15+max_y/100, label='**', size=7)+ # tar
  #   geom_segment(aes(x =1.9, y = max_y+max_y/15, xend = 2.1, yend = max_y+max_y/15), size= 1) # top line
  # # annotate('text', x=2, y=max_y+max_y/15+max_y/100, label='*', size=7) # star
ggsave(pl, file=paste0(plotPrefix, "PVT_Plot.jpeg"), width = 2500, height = 1500, dpi = 300, units = "px")
pl
```
--------------------------------------------------------------
```{r message=FALSE, warning = FALSE}
##########################################
  ### VAS-f: fatigue ###
#########################################
# = subjective measure of fatigue on 1-10 scale
# we want to know if there is a difference in VAS before and after Test

#### DOWNLOAD + CLEAN DATA ####
data <- read.csv(paste0(Dir, "VAS.csv"), header = TRUE, sep = )
data <-data[(grepl("quantised", data$Question.Key)),] #VAS has 'quantised: 1-11 instead of 0-10

VAS <- as.data.frame(group_by(data, Test, Day, Condition, ID) %>%
  summarise(
    count = n(),
    Mean = mean(Response, na.rm = TRUE)
  )) # we do Mean instead of Difference 2-1/1. Reason: this led to non-normal data

#factors
VAS$Day <- as.factor(VAS$Day)
VAS$Condition <- as.factor(VAS$Condition)
VAS$ID <- as.factor(VAS$ID)
names(VAS)[names(VAS)=="Test"] <- "Time"
VAS$Time <- as.factor(VAS$Time)


### CHECKING ASSUMPTIONS ####
# Time x Condition 2-way ANOVA with interaction effect (what Borrogan did)
res.aov2 <- aov(Mean ~ Condition * Day, data= VAS)
summary(res.aov2)# no sign! this is good, means vigilance was same in all conditions

# HOMOGENEITY OF VARIANCE
plot(res.aov2, 1) # residuqls vs fits plot shows no evident relationship residuals and fitted values (means of groups)

# NORMALITY
aov_residuals <- residuals (object=res.aov2)
shapiro.test(x=aov_residuals) #  
VAS %>%
  group_by(Condition, Day) %>%
  shapiro_test(Mean) # 
#visualisation
plot(res.aov2, 2) #normal
ggqqplot(VAS, "Mean", ggtheme = theme_bw()) +
  facet_grid(Day ~ Condition)
ggqqplot(VAS, "Mean", ggtheme = theme_bw()) +
  facet_grid( ~Condition) #  very obviously NOT a normal distribution

# SPHERICITY: Mauchly's test
x<-anova_test(data= VAS, dv= Mean, wid= ID, between= Condition, within= c(Time, Day))
get_anova_table(x, correction = c('GG')) #variances are NOT equal! 
x$'Sphericity Corrections'

# OUTLIERS
summary(VAS$Mean)
outliers <- boxplot(VAS$Mean, plot=FALSE)$out
#visualise
d<-melt(data.frame(VAS=c(VAS$Mean))) # we melt to wide format
distribution_plot (d, 'Mean')
qqPlot(VAS$Mean) 


#### repeated-measures ANOVA ####
get_anova_table(x)

#tukey's post-hoc analyses: see if performance decreased faster in HCL compared to LCL
three_w <- lm(Mean ~ Time*Condition*Day, data= VAS)
exp.av <- aov(three_w)
summary(exp.av)
tukey.test <- TukeyHSD(exp.av)
tukey.test$Time #t1 > t4 & t5, t2 >t4 & t5!

emmeans1<- emmeans(three_w, pairwise ~ Time*Condition*Day, adjust ="fdr", type = "response")
emmean_dataframe <- summary(emmeans1)$emmeans

Anova(three_w, type='III')
summary(emmeans1)

#summary 
sum <- sum_3 (VAS, 'Time', 'Condition', 'Day', 'Mean')
sum

## VISUALISATION
# boxplot 
bxp <- ggboxplot(
  VAS, x = "Condition", y = "Mean",
  color = "Time", palette = "jco",
  facet.by = "Day", short.panel.labs = FALSE
  )
## plot with error bars
max_y<-max(VAS$Mean)
pl <- plotty(VAS, emmean_dataframe, 'Time', 'Mean', 'Condition', 'emmean', 'subj CF') +
 facet_grid(.~Day)+
scale_x_discrete(labels=c("Before", "After"))
ggsave(pl, file=paste0(plotPrefix, "VAS_Plot.jpg"), width = 2500, height = 1500, dpi = 300, units = "px")
pl
```

-----------------------------------------------------------------------------------

```{r message=FALSE, warning = FALSE}

##########################################
  ### PERFORMANCE/ ACCURACY/ OBJECTIVE CF ###
#########################################
# We will test Performance (weighted accuracy) with Condition (HCL/LCL) and Time (t1-t3) as within-subject factors.
# interested in main effect e.g. t1>t4 and Condition x Time interaction on the Acc

#### PREPARATION ####

## DOWNLOAD + CLEAN DATA
data<- read.csv(paste0(Dir, "EXP.csv"), header = TRUE, sep = )
# we remove rows that have prop_correct == NA , because these are lines in the data where the ERROR message was shown (accuracy=0)
data <- data[!is.na(data$prop_correct),]
# create a trial.index that goes from 1 to the number of trials:  not every participant has equal amount of trials, depends on their speed/accuracy
for (i in 1:97) {
  data$trial.index[data$ID==i]= 1:length(unique(data$Trial.Index[data$ID ==i]))
}
length(data$trial.index[is.na(data$trial.index)]) # check number of NA's, should be 0
#remove some unnecessary columns
data = subset(data, select = -c(Local.Date, Participant.Private.ID, Task.Name, Accuracy_Level, Time.Elapsed, Trial.Index))

## WEIGHTED ACCURACY
# = the evolution of performance during TloadDback
# create var Time that indicates if it is part of t1, t2, t3. t1 is the first 40%, t2 middle 20%, t3 last 40% 
# we need to work with percents because the #trials differs per ptt AND per day: 
for (i in 1:97) {
  data$Time[data$ID ==i & data$Day==1] = "t3" # day 1
  data$Time[data$ID ==i & data$Day==1 & data$trial.index<(0.6* length(data$trial.index[data$Day==1 & data$ID==i])) ] = "t2"
  data$Time[data$ID ==i & data$Day==1 & data$trial.index<(0.4* length(data$trial.index[data$Day==1 & data$ID==i])) ] = "t1"
   
  data$Time[data$ID ==i & data$Day==2] = "t3" # day 2
  data$Time[data$ID ==i & data$Day==2 & data$trial.index<(0.6* length(data$trial.index[data$Day==2 & data$ID==i])) ] = "t2"
  data$Time[data$ID ==i & data$Day==2 & data$trial.index<(0.4* length(data$trial.index[data$Day==2 & data$ID==i])) ] = "t1"
}
length(data$Time[is.na(data$Time)]) #NAs, should be 0


## CREATE DATAFRAME  with the Acc prop_correct per ID, Time, Day, Condition
EXP <- group_by(data, Condition, Day, Time, ID) %>%
  summarise(
    count = n(),
    Mean = mean(prop_correct, na.rm = TRUE)
  )
EXP <- as.data.frame(EXP)
head(EXP) # mean Mean (prop_correct) per ID, Time, Day and Condition

# set factors
EXP$Time <- as.factor(EXP$Time)
EXP$Condition <- as.factor(EXP$Condition)
EXP$Day <- as.factor(EXP$Day)
EXP$ID <- as.factor(EXP$ID)



### CHECKING ASSUMPTIONS ####

# Time x Condition 2-way ANOVA with interaction effect
res.aov2 <- aov(Mean ~ Condition*Time, data= EXP)
summary(res.aov2)

## HOMOGENEITY OF VARIANCE
#Levene's test homogeneity variances
leveneTest(Mean~ Time * Condition, data= EXP) # no homogeneity! problem! 
box_m(EXP[, 'Mean', drop=FALSE], EXP$Condition) # no homogeneity of variance
#visualisation
plot(res.aov2, 1) # residuqls vs fits plot shows no evident relationship residuals and fitted values (means of groups)

## NORMALITY
aov_residuals <- residuals (object=res.aov2)
shapiro.test(x=aov_residuals) # no normality! 
EXP %>%
  group_by(Condition, Time) %>%
  shapiro_test(Mean) # no normal distribution!
#visualisation
plot(res.aov2, 2) #clearly not normal
ggqqplot(EXP, "Mean", ggtheme = theme_bw()) +
  facet_grid(Time ~ Condition)
ggqqplot(EXP, "Mean", ggtheme = theme_bw()) +
  facet_grid( ~Condition) #  very obviously NOT a normal distribution

## SPHERICITY: Mauchly's test
x<-anova_test(data= EXP, dv= Mean, wid= ID, between= Condition, within= c(Time, Day))
get_anova_table(x, correction = c('GG')) #variances are NOT equal! 
x$'Sphericity Corrections'

## OUTLIERS
EXP %>%
  group_by(Condition, Time) %>%
  identify_outliers(Mean)
 outliers <- boxplot(EXP$prop_correct, plot=FALSE)$out
summary(EXP$Mean)
outliers <- boxplot(EXP$Mean, plot=FALSE)$out

#remove outliers? Maybe not necessary
#remove under 3? (sign not paying attention? a bit arbitrary)
#EXP <-  EXP[!EXP$Mean<0.3,]
#remove outliers outside of quantiles
list_quantiles <- tapply(EXP$Mean, EXP$Condition, quantile)
Q1s <- sapply(1:2, function(i) list_quantiles[[i]][2])
Q3s <- sapply(1:2, function(i) list_quantiles[[i]][4])
IQRs <- tapply(EXP$Mean, EXP$Condition, IQR)
Lowers <- Q1s - 1.5*IQRs
Uppers <- Q3s + 1.5*IQRs
datas <- split(EXP, EXP$Condition)
data_no_outlier <- NULL
for (i in 1:2){
out <- subset(datas[[i]], datas[[i]]$Mean > Lowers[i] & datas[[i]]$Mean < Uppers[i])
data_no_outlier <- rbind(data_no_outlier, out)
}
EXP<- as.data.frame(data_no_outlier)

# Also: unbalanced design! not equal amount in each group
length(unique(EXP$ID[EXP$Condition=='LCL']))
length(unique(EXP$ID[EXP$Condition=='HCL']))

## SOLUTION: 
#even after log transform and removing outliers we have clearly not a normal distribution 
# so we need to use GLM. https://stats.stackexchange.com/questions/189115/fitting-a-binomial-glmm-glmer-to-a-response-variable-that-is-a-proportion-or-f
#BINOMIAL because the Meanuracy is between 0 and 1
# it is a (continuous) proportion: we need to use the 'weights' argument for the number of trials that lead to the proportion


### CONDITION * TIME ###

## STATISTICAL TEST
two_w <- glmer(Mean ~ Condition * Time + (1 | ID), weights = count,
   family = binomial, data = EXP)
emmeans1<- emmeans(two_w, pairwise ~ Condition * Time, adjust ="fdr", type = "response")
emmean_dataframe <- summary(emmeans1)$emmeans

Anova(two_w, type='III')
summary(emmeans1)
#summary 
sum <- sum_2 (EXP, 'Time', 'Condition', 'Mean')
sum

## VISUALISATION
# boxplot 
bxp <- ggboxplot(
  EXP, x = "Time", y = "Mean",
  color = "Condition", palette = "jco")
bxp

## plot with error bars
pl <- plotty(EXP, emmean_dataframe, 'Time',  'Mean', 'Condition', 'prob', 'Performance/Objective CF') +
  facet_grid(.~Day)
pl

### CONDITION ###
## STATISTICAL TEST
one_w <- glmer(Mean ~ Condition  + (1 | ID), weights = count,
   family = binomial, data = EXP)
emmeans1<- emmeans(one_w, pairwise ~ Condition, adjust ="fdr", type = "response")
emmean_dataframe <- summary(emmeans1)$emmeans

Anova(one_w, type='III')
summary(emmeans1)# LCL clearly has higher Mean: 0.89 for LCL and 0.62 for HCL

##VISUALISATION
# boxplot 
bxp <- ggboxplot(
  EXP, x = "Condition", y = "Mean", palette = "jco")
bxp

#  plot
pl <- one_w_plot(EXP, emmean_dataframe, 'Condition', 'Mean', 'prob', 'Performance/Objective CF')
pl


####  DAY 1 vs DAY 2 #####

## STATISTICAL TEST
two_w <- glmer(Mean ~ Condition * Day + (1 | ID), weights = count,
   family = binomial, data = EXP)
emmeans1<- emmeans(two_w, pairwise ~ Condition * Day, adjust ="fdr", type = "response")
emmean_dataframe <- summary(emmeans1)$emmeans

Anova(two_w, type='III')
summary(emmeans1)
#summary  
sum <- sum_2 (EXP, 'Day', 'Condition', 'Mean')
sum

## VISUALISATION
# plot with error bars
plot <- plotty(EXP, emmean_dataframe, 'Day',  'Mean', 'Condition', 'prob', 'Perfromance/Objective CF') 
plot


### COMPONENTS (Color/Pic)####
# evolution over time for 2 components of the task
# Pics: decide if big/small. Color: decide if same as DualBack: more Working Memory
# Stim * Condition * Time as within-subj factors
# interaction and main effect
# to indicate higher complexity WMM component (pics) compared to balls 

EXP <- group_by(data, Condition, Day, Time, ID, Stim) %>%
  summarise(
    count = n(),
    Mean = mean(prop_correct, na.rm = TRUE)
  )
EXP <- as.data.frame(EXP)
head(EXP) # mean Mean (prop_correct) per ID, Time, Day and Condition

# set factors
EXP$Time <- as.factor(EXP$Time)
EXP$Condition <- as.factor(EXP$Condition)
EXP$Day <- as.factor(EXP$Day)
EXP$ID <- as.factor(EXP$ID)
EXP$Stim <- as.factor(EXP$Stim)

## STATISTICAL TEST
two_w <- glmer(Mean ~ Condition * Time * Stim + (1 | ID), weights = count,
   family = binomial, data = EXP)
emmeans1<- emmeans(two_w, pairwise ~ Condition * Time * Stim, adjust ="fdr", type = "response")
emmean_dataframe <- summary(emmeans1)$emmeans

Anova(two_w, type='III')
summary(emmeans1)
# summary
sum <- sum_2 (EXP, 'Stim', 'Condition', 'Mean')
sum


## VISUALISATION
# not really intuitive because 3-way interaction

## CORR Mean score between two conditions (HCL and LCL)

```


-----------------------------------------------------------------------------------

```{r message=FALSE, warning = FALSE}
##########################################
  ### CORRELATIONS ###
#########################################

### Correlation plot ####


### CORR VAS-f difference score between two conditions (HCL and LCL)


## CORR Mean score between two conditions (HCL and LCL)


## Pearson coeff  between delta (change) of VASf and delta (change) of Mean during first/second half 

## Test-restest corr betweeen VAS f Day 1 and Day 2 in HCL and LCL

# Test-restest corr Mean day 1 and day 2 in HCL and LCL

## correlation VASf with PVT

## corr VASf with Mean

## Corr PVT with Mean

cor.test(my_data$wt, my_data$mpg,  method="kendall") # not Pearson because: not normal distribution
cor.test(my_data$wt, my_data$mpg,  method = "spearman") # or Spearman

### Correlation plot ####
overall_corr <- function(var1, var2, x_lab, y_lab) {
  dataframe <- data.frame(var1, var2)
  ggscatter(dataframe, x = var1, y = var2,
            add='reg.line', fullrange=TRUE,
            conf.int=TRUE,
            cor.coef=TRUE, cor.method='pearson',
            xlab=x_lab, ylab=y_lab)+
    geom_segment(aes(x = -4, y = -4, xend = 40, yend = 40), size= 1, colour='red')
}

var1<- VAS$Diff[VAS$Condition=='HCL']
var2<- VAS$Diff[VAS$Condition=='LCL']
x_lab= 'VAS-f HCL'
y_lab= 'VAS-f LCL'
dataframe <- data.frame(var1, var2)
  ggscatter(dataframe, x = var1, y = var2,
            add='reg.line', fullrange=TRUE,
            conf.int=TRUE,
            cor.coef=TRUE, cor.method='pearson',
            xlab=x_lab, ylab=y_lab)+
    geom_segment(aes(x = -4, y = -4, xend = 40, yend = 40), size= 1, colour='red')


overall_corr(PSS, PTQ, x_lab, y_lab)

## delta
# PMS
PSS <- data$PSS[data$PMS=='PMS'&data$Moment=='Foll']-data$PSS[data$PMS=='PMS'&data$Moment=='Lut']
PTQ <- data$PTQ[data$PMS=='PMS'&data$Moment=='Foll']-data$PTQ[data$PMS=='PMS'&data$Moment=='Lut']
x_lab = 'PMS_delta_PSS'
y_lab = 'PMS_delta_PTQ'
overall_corr(PSS, PTQ, x_lab, y_lab)


