---
title: "Short_TloadDback"
author: "Sofie Raeymakers"
date: "`r Sys.setlocale('LC_TIME', 'C'); format(Sys.time(), '%d\\\\. %B %Y')`"
runtime: shiny
output: 
  html_document:
    keep_md: yes
---


<style type="text/css">
.main-container {
  max-width: 1800px;
  margin-left: auto;
  margin-right: auto;
}
</style>

```{r setup, include=FALSE}
rm(list = ls()) # Clear environment
cat("\014") # Clear console
knitr::opts_chunk$set(echo = TRUE)
```
# A Data Analysis Report {.tabset}
```{r message=FALSE, warning = FALSE}
##### Set environment #####

# Install packages
list.of.packages <- c('tidyverse', 'effects', 'emmeans', 'data.table', 'dplyr', 'lme4', 'ggplot2', 'MuMIn', 'effsize', 'reshape2',
                      'cowplot', 'car', 'ggpubr', 'rstatix') # All relevant packages
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])] # Check if any of these packages are not yet installed
if(length(new.packages)) install.packages(new.packages) # If any packages are not yet installed, install them

library(tidyverse)
library(effects)
library(emmeans)
library(data.table)
library(dplyr)
library(lme4)
library(ggplot2)
library(MuMIn)
library(effsize)
library(reshape2)
library(cowplot)
library(car)
library(ggpubr)
library(rstatix)

# Get and declare functions
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source("C:/Users/ASUSTeK/OneDrive/Documenten/Github/Short_TLoadDBack/functions.R") # file in the same directory for functions so they're together
#Set working directory to the folder in which all CSV files are located
Dir = "C:/Users/ASUSTeK/OneDrive/Documenten/Github/Short_TLoadDBack/Data/"
setwd(Dir)

# save figures
if (!dir.exists("figures")){ # Create folder for storing the figures if it doesn't exist yet
  dir.create("figures")}
plotPrefix <- paste0(Dir,"figures/") # Prefix to easily store figures later
```

Sofie Raeymakers


***

## Intro

explaination study

### Vigilance

we want to see if PVT/vigilance is different in day 1 compared to day 2 and in HCl compared to LCl (Condition) before the test

##### subtitle


```{r PVT, message=FALSE, warning = FALSE}
##########################################
  ### PVT/VIGILANCE/RT ###
#########################################

#### DOWNLOAD + CLEAN DATA ####

#Download PVT data (this datafile is made in 'preprocessing')
data <- read.csv(paste0(Dir, "PVT.csv"), header = TRUE, sep = )
# mean 1/RT
data$RT <- 1/(data$RT/1000) #1/RT  ==> other result

## CREATE DATAFRAME  with the MeanRT per ID, Day, Condition
PVT <- as.data.frame(group_by(data, Test, Day, Condition, ID) %>%
  summarise(
    count = n(),
    Mean = mean(RT, na.rm = TRUE)
  ))
PVT <- PVT[!(PVT$Test==2),] # we will only look at before-test measures

# visualise RT's: from 0 to 10 seconds 
d<-melt(data.frame(RT=c(PVT$Mean))) # we melt to wide format
distribution_plot (d, 'Mean')
qqPlot(PVT$Mean) # clearly not a normal distribution: a big skew 

# make factors
PVT$Day <- factor(PVT$Day)
PVT$ID <- factor(PVT$ID)
PVT$Condition <- factor(PVT$Condition)


### CHECKING ASSUMPTIONS ####
# Time x Condition 2-way ANOVA with interaction effect (what Borrogan did)
res.aov2 <- aov(Mean ~ Condition * Day, data= PVT)
summary(res.aov2)# no sign! this is good, means vigilance was same in all conditions

# HOMOGENEITY OF VARIANCE
plot(res.aov2, 1) # residuqls vs fits plot shows no evident relationship residuals and fitted values (means of groups)

# NORMALITY
aov_residuals <- residuals (object=res.aov2)
shapiro.test(x=aov_residuals) # no normality! 
# PVT %>%
#   group_by(Condition, Day) %>%
#   shapiro.test(Mean) # no normal distribution!
#visualisation
plot(res.aov2, 2) #clearly not normal
ggqqplot(PVT, "Mean", ggtheme = theme_bw()) +
  facet_grid(Day ~ Condition)
ggqqplot(PVT, "Mean", ggtheme = theme_bw()) +
  facet_grid( ~Condition) #  very obviously NOT a normal distribution

# OUTLIERS
summary(PVT$Mean)
outliers <- boxplot(PVT$Mean, plot=FALSE)$out
# remove 
PVT<- PVT[-which(PVT$Mean %in% outliers),]
#visualise
d<-melt(data.frame(RT=c(PVT$Mean))) # we melt to wide format
distribution_plot (d, 'Mean') # much better
qqPlot(PVT$Mean) # much better


### ANALYSIS ###
#https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01171/full
#https://stats.stackexchange.com/questions/254361/modeling-reaction-time-with-glmer
# => glmer with inverse link: can handle RT that is not normally distributed
d0.1 <- glmer (Mean~Condition * Day  + (1|ID), data= PVT, family= inverse.gaussian(link="identity"))
d0.2<- glmer (Mean~Condition * Day  + (1|ID), data= PVT, family= Gamma)
d0.3 <- glmer (Mean~Condition * Day  + (1|ID), data= PVT, family= gaussian)
tabel <- cbind(AIC(d0.1, d0.2, d0.3)) 
two_w<- glmer (Mean~Condition * Day  + (1|ID), data= PVT, family= Gamma)
emmeans1<- emmeans(two_w, pairwise ~ Condition * Day, adjust ="fdr", type = "response")
emmean_dataframe <- summary(emmeans1)$emmeans

Anova(two_w, type='III')
summary(emmeans1) ## Result the SAME for data with or without outliers (PVT & PVT2): because it is glmer
# but removing the outliers makes visualisations much more readable
#summary 
sum <- sum_2 (PVT, 'Day', 'Condition', 'Mean')
sum


### VISUALISATION ###
# boxplot 
bxp <- ggboxplot(
  PVT, x = "Day", y = "Mean",
  color = "Condition", palette = "jco")
bxp

## plot with error bars
pl <- plotty(PVT, emmean_dataframe, 'Day',  'Mean', 'Condition', 'response', 'Vigilance') 
  #   geom_segment(aes(x =0.9, y = max_y+max_y/15, xend = 1.1, yend = max_y+max_y/15), size= 1)+ # top line
  # annotate('text', x=1, y=max_y+max_y/15+max_y/100, label='**', size=7)+ # tar
  #   geom_segment(aes(x =1.9, y = max_y+max_y/15, xend = 2.1, yend = max_y+max_y/15), size= 1) # top line
  # # annotate('text', x=2, y=max_y+max_y/15+max_y/100, label='*', size=7) # star
ggsave(pl, file=paste0(plotPrefix, "PVT_Plot.jpeg"), width = 2500, height = 1500, dpi = 300, units = "px")
pl
```
--------------------------------------------------------------

## Subjective CF: VAS-f

= subjective measure of fatigue on 1-10 scale
we want to know if there is a difference in VAS before and after Test

```{r VASf, message=FALSE, warning = FALSE}
##########################################
  ### VAS-f: fatigue ###
#########################################

#### DOWNLOAD + CLEAN DATA ####
data <- read.csv(paste0(Dir, "VAS.csv"), header = TRUE, sep = )
data <-data[(grepl("quantised", data$Question.Key)),] #VAS has 'quantised: 1-11 instead of 0-10
# create dataframe
VAS <- as.data.frame(group_by(data, Test, Day, Condition, ID) %>%
  summarise(
    count = n(),
    Mean = mean(Response, na.rm = TRUE)
  )) # we do Mean instead of Difference 2-1/1. Reason: this led to non-normal data


#factors
VAS$Day <- as.factor(VAS$Day)
VAS$Condition <- as.factor(VAS$Condition)
VAS$ID <- as.factor(VAS$ID)
names(VAS)[names(VAS)=="Test"] <- "Time"
VAS$Time <- as.factor(VAS$Time)

### CHECKING ASSUMPTIONS ####
# Time x Condition 2-way ANOVA with interaction effect (what Borrogan did)
res.aov2 <- aov(Mean ~ Condition * Day, data= VAS)
summary(res.aov2)# no sign! this is good, means vigilance was same in all conditions

# HOMOGENEITY OF VARIANCE
leveneTest(Mean~ Time * Condition, data= VAS) # no homogeneity! problem! 
# box_m(VAS[, 'Mean', drop=FALSE], VAS$Condition) 
plot(res.aov2, 1) # residuqls vs fits plot shows no evident relationship residuals and fitted values (means of groups)

# NORMALITY
aov_residuals <- residuals (object=res.aov2)
shapiro.test(x=aov_residuals) #  
# VAS %>%
#   group_by(Condition, Day) %>%
#   shapiro.test(Mean) # 
#visualisation
plot(res.aov2, 2) #normal
ggqqplot(VAS, "Mean", ggtheme = theme_bw()) +
  facet_grid(Day ~ Condition)
ggqqplot(VAS, "Mean", ggtheme = theme_bw()) +
  facet_grid( ~Condition) #  very obviously NOT a normal distribution

# SPHERICITY: Mauchly's test
x<-anova_test(data= VAS, dv= Mean, wid= ID, between= Condition, within= c(Time, Day))
get_anova_table(x, correction = c('GG')) #variances are NOT equal! 
x$'Sphericity Corrections'

# OUTLIERS
summary(VAS$Mean)
outliers <- boxplot(VAS$Mean, plot=FALSE)$out
#visualise
d<-melt(data.frame(VAS=c(VAS$Mean))) # we melt to wide format
distribution_plot (d, 'Mean')
qqPlot(VAS$Mean) 


#### repeated-measures ANOVA ####
get_anova_table(x)

#tukey's post-hoc analyses: see if performance decreased faster in HCL compared to LCL
two_w <- lm(Mean ~ Time*Condition, data= VAS)
exp.av <- aov(two_w)
summary(exp.av)
tukey.test <- TukeyHSD(exp.av)
tukey.test$Time 
emmeans1<- emmeans(two_w, pairwise ~ Time*Condition, adjust ="fdr", type = "response")
emmean_dataframe <- summary(emmeans1)$emmeans
Anova(two_w, type='III')
summary(emmeans1)

three_w <- lm(Mean ~ Time*Condition*Day, data= VAS)
exp.av <- aov(three_w)
summary(exp.av)
tukey.test <- TukeyHSD(exp.av)
tukey.test$Time #t1 > t4 & t5, t2 >t4 & t5!
emmeans1<- emmeans(three_w, pairwise ~ Time*Condition*Day, adjust ="fdr", type = "response")
emmean_dataframe <- summary(emmeans1)$emmeans
Anova(three_w, type='III')
summary(emmeans1)

#summary 
sum <- sum_3 (VAS, 'Time', 'Condition', 'Day', 'Mean')
sum

## VISUALISATION
# boxplot 
bxp <- ggboxplot(
  VAS, x = "Condition", y = "Mean",
  color = "Time", palette = "jco",
  facet.by = "Day", short.panel.labs = FALSE
  )
## plot with error bars
pl <- plotty(VAS, emmean_dataframe, 'Time', 'Mean', 'Condition', 'emmean', 'subj CF') +
 facet_grid(.~Day)+
scale_x_discrete(labels=c("Before", "After"))
ggsave(pl, file=paste0(plotPrefix, "VAS_Plot.jpg"), width = 2500, height = 1500, dpi = 300, units = "px")
pl


# 
# # difference score, devide by baseline (pre TloadBack) as a function of group (Day/condition): (2-1)/1
# for (i in 1:97) {
#   VAS$Diff[VAS$ID==i & VAS$Day==1] = 
#     ((VAS$Mean[VAS$Test==2 & VAS$ID==i & VAS$Day==1]- VAS$Mean[VAS$Test==1 & VAS$ID==i & VAS$Day==1])/VAS$Mean[VAS$Test==1 & VAS$ID==i & VAS$Day==1])
#   VAS$Diff[VAS$ID==i & VAS$Day==2] = 
#     ((VAS$Mean[VAS$Test==2 & VAS$ID==i & VAS$Day==1]- VAS$Mean[VAS$Test==1 & VAS$ID==i & VAS$Day==2])/VAS$Mean[VAS$Test==1 & VAS$ID==i & VAS$Day==2])
# }
# ### CHECKING ASSUMPTIONS ####
# # Time x Condition 2-way ANOVA with interaction effect (what Borrogan did)
# res.aov2 <- aov(Diff ~ Condition * Day, data= VAS)
# summary(res.aov2)
# # HOMOGENEITY OF VARIANCE
# plot(res.aov2, 1) # residuqls vs fits plot shows no evident relationship residuals and fitted values (Diffs of groups)
# 
# # NORMALITY
# aov_residuals <- residuals (object=res.aov2)
# shapiro.test(x=aov_residuals) #  
# VAS %>%
#   group_by(Condition, Day) %>%
#   shapiro_test(Diff) # 
# #visualisation
# plot(res.aov2, 2) #normal
# ggqqplot(VAS, "Diff", ggtheme = theme_bw()) +
#   facet_grid(Day ~ Condition)
# ggqqplot(VAS, "Diff", ggtheme = theme_bw()) +
#   facet_grid( ~Condition) #  very obviously NOT a normal distribution
# 
# # SPHERICITY: Mauchly's test
# x<-anova_test(data= VAS, dv= Diff, wid= ID, between= Condition, within= c(Time, Day))
# get_anova_table(x, correction = c('GG')) #variances are NOT equal! 
# x$'Sphericity Corrections'
# 
# # OUTLIERS
# summary(VAS$Diff)
# outliers <- boxplot(VAS$Diff, plot=FALSE)$out
# # remove 
#  VAS<- VAS[-which(VAS$Diff %in% outliers),]
# #visualise
# d<-melt(data.frame(VAS=c(VAS$Diff))) # we melt to wide format
# distribution_plot (d, 'Diff')
# qqPlot(VAS$Diff) 
# 
# 
# #### repeated-measures ANOVA ####
# x<-anova_test(data= VAS, dv= Diff, wid= ID, between= Condition, within= c(Time, Day))
# get_anova_table(x)
# 
# #tukey's post-hoc analyses: see if performance decreased faster in HCL compared to LCL
# two_w <- lm(Diff ~ Time*Condition, data= VAS)
# exp.av <- aov(two_w)
# summary(exp.av)
# tukey.test <- TukeyHSD(exp.av)
# tukey.test$Time 
# emmeans1<- emmeans(two_w, pairwise ~ Time*Condition, adjust ="fdr", type = "response")
# emDiff_dataframe <- summary(emmeans1)$emmeans
# Anova(two_w, type='III')
# summary(emmeans1)
# 
# #summary 
# sum <- sum_3 (VAS, 'Time', 'Condition', 'Day', 'Diff')
# sum
# 
# ## VISUALISATION
# # boxplot 
# bxp <- ggboxplot(
#   VAS, x = "Condition", y = "Diff",
#   color = "Time", palette = "jco",
#   facet.by = "Day", short.panel.labs = FALSE
#   )
# ## plot with error bars
# pl <- plotty(VAS, emmean_dataframe, 'Day', 'Diff', 'Condition', 'emmean', 'subj CF')
# scale_x_discrete(labels=c("Before", "After"))


```

-----------------------------------------------------------------------------------

## Objective CF

* We will test  the evolution of Performance (weighted accuracy) during TloadDback with Condition (HCL/LCL) and Time (t1-t3) as within-subject factors.
* interested in main effect e.g. t1>t4 and Condition x Time interaction on the Acc

```{r Performance, message=FALSE, warning = FALSE}
##########################################
  ### PERFORMANCE/ ACCURACY/ OBJECTIVE CF ###
#########################################

#### DOWNLOAD + CLEAN DATA ####
data<- read.csv(paste0(Dir, "EXP.csv"), header = TRUE, sep = )
# we remove rows that have prop_correct == NA , because these are lines in the data where the ERROR message was shown (accuracy=0)
data <- data[!is.na(data$prop_correct),]
# create a trial.index that goes from 1 to the number of trials:  not every participant has equal amount of trials, depends on their speed/accuracy
for (i in 1:97) { data$trial.index[data$ID==i]= 1:length(unique(data$Trial.Index[data$ID ==i]))}

# length(data$trial.index[is.na(data$trial.index)]) 
# data = subset(data, select = -c(Local.Date, Participant.Private.ID, Task.Name, Accuracy_Level, Time.Elapsed, Trial.Index))

# create var Time that indicates if it is part of t1, t2, t3. t1 is the first 40%, t2 middle 20%, t3 last 40% 
# we work with percentages because the #trials differs per ptt AND per day: 
for (i in 1:97) {
  data$Time[data$ID ==i & data$Day==1] = 2 # day 1
  data$Time[data$ID ==i & data$Day==1 & data$trial.index<(0.6* length(data$trial.index[data$Day==1 & data$ID==i])) ] = "middle"
  data$Time[data$ID ==i & data$Day==1 & data$trial.index<(0.4* length(data$trial.index[data$Day==1 & data$ID==i])) ] = 1
  data$Time[data$ID ==i & data$Day==2] = 2 # day 2
  data$Time[data$ID ==i & data$Day==2 & data$trial.index<(0.6* length(data$trial.index[data$Day==2 & data$ID==i])) ] = "middle"
  data$Time[data$ID ==i & data$Day==2 & data$trial.index<(0.4* length(data$trial.index[data$Day==2 & data$ID==i])) ] = 1
}
#remove 'middle'
data <- data[!(data$Time=="middle"),]
# CREATE DATAFRAME, with the Mean prop_correct per ID, Time, Day, Condition
EXP <- as.data.frame (group_by(data, Condition, Day, Time, ID) %>%
  summarise(
    count = n(),
    Mean = mean(prop_correct, na.rm = TRUE)
  ))
head(EXP) # mean Mean (prop_correct) per ID, Time, Day and Condition

# set factors
EXP$Time <- as.factor(EXP$Time)
EXP$Condition <- as.factor(EXP$Condition)
EXP$Day <- as.factor(EXP$Day)
EXP$ID <- as.factor(EXP$ID)


### CHECKING ASSUMPTIONS ####

# Time x Condition 2-way ANOVA with interaction effect
res.aov2 <- aov(Mean ~ Condition*Time, data= EXP)
summary(res.aov2)

## HOMOGENEITY OF VARIANCE
#Levene's test homogeneity variances
leveneTest(Mean~ Time * Condition, data= EXP) # no homogeneity! problem! 
box_m(EXP[, 'Mean', drop=FALSE], EXP$Condition) # no homogeneity of variance
#visualisation
plot(res.aov2, 1) # residuqls vs fits plot shows no evident relationship residuals and fitted values (means of groups)

## NORMALITY
aov_residuals <- residuals (object=res.aov2)
shapiro.test(x=aov_residuals) # no normality! 
# EXP %>%
#   group_by(Condition, Time) %>%
#   shapiro.test(Mean) # no normal distribution!
#visualisation
plot(res.aov2, 2) #clearly not normal
ggqqplot(EXP, "Mean", ggtheme = theme_bw()) +
  facet_grid(Time ~ Condition)
ggqqplot(EXP, "Mean", ggtheme = theme_bw()) +
  facet_grid( ~Condition) #  very obviously NOT a normal distribution

## SPHERICITY: Mauchly's test
x<-anova_test(data= EXP, dv= Mean, wid= ID, between= Condition, within= c(Time, Day))
get_anova_table(x, correction = c('GG')) #variances are NOT equal! 
x$'Sphericity Corrections'

## OUTLIERS
EXP %>%
  group_by(Condition, Time) %>%
  identify_outliers(Mean)
 outliers <- boxplot(EXP$prop_correct, plot=FALSE)$out
summary(EXP$Mean)
#remove under e.g. 3? (sign not paying attention? a bit arbitrary)
#EXP <-  EXP[!EXP$Mean<0.3,]
#remove outliers per condition (HCL/LCL) because they have different distributions! 
list_quantiles <- tapply(EXP$Mean, EXP$Condition, quantile)
Q1s <- sapply(1:2, function(i) list_quantiles[[i]][2])
Q3s <- sapply(1:2, function(i) list_quantiles[[i]][4])
IQRs <- tapply(EXP$Mean, EXP$Condition, IQR)
Lowers <- Q1s - 1.5*IQRs
Uppers <- Q3s + 1.5*IQRs
datas <- split(EXP, EXP$Condition)
data_no_outlier <- NULL
for (i in 1:2){
  out <- subset(datas[[i]], datas[[i]]$Mean > Lowers[i] & datas[[i]]$Mean < Uppers[i])
  data_no_outlier <- rbind(data_no_outlier, out)}
EXP<- as.data.frame(data_no_outlier)
#even after log transform and removing outliers we have clearly not a normal distribution 
# so we need to use GLM. https://stats.stackexchange.com/questions/189115/fitting-a-binomial-glmm-glmer-to-a-response-variable-that-is-a-proportion-or-f

### CONDITION * TIME ###
# HCLvs LCL over time
#BINOMIAL because the Mean accuracy is between 0 and 1
# it is a (continuous) proportion: we need to use the 'weights' argument for the number of trials that lead to the proportion
two_w <- glmer(Mean ~ Condition * Time + (1 | ID), weights = count,
   family = binomial, data = EXP)
emmeans1<- emmeans(two_w, pairwise ~ Condition * Time, adjust ="fdr", type = "response")
emmean_dataframe <- summary(emmeans1)$emmeans
Anova(two_w, type='III')
summary(emmeans1)
#summary 
sum <- sum_2 (EXP, 'Time', 'Condition', 'Mean')
sum

## VISUALISATION
# boxplot 
bxp <- ggboxplot(
  EXP, x = "Time", y = "Mean",
  color = "Condition", palette = "jco")
bxp

max_y<-max(EXP$Mean)
pl <- plotty(EXP, emmean_dataframe, 'Time',  'Mean', 'Condition', 'prob', 'Performance/Objective CF') 
  #   geom_segment(aes(x =0.9, y = max_y+max_y/15, xend = 1.1, yend = max_y+max_y/15), size= 1)+ # top line
  # annotate('text', x=1, y=max_y+max_y/15+max_y/100, label='**', size=7)+ # tar
  #   geom_segment(aes(x =1.9, y = max_y+max_y/15, xend = 2.1, yend = max_y+max_y/15), size= 1) # top line
  # # annotate('text', x=2, y=max_y+max_y/15+max_y/100, label='*', size=7) # star
ggsave(pl, file=paste0(plotPrefix, "Acc_Cond_Time_Plot.jpg"), width = 2500, height = 1500, dpi = 300, units = "px")
pl



### CONDITION ###
one_w <- glmer(Mean ~ Condition  + (1 | ID), weights = count,
   family = binomial, data = EXP)
emmeans1<- emmeans(one_w, pairwise ~ Condition, adjust ="fdr", type = "response")
emmean_dataframe <- summary(emmeans1)$emmeans

Anova(one_w, type='III')
summary(emmeans1)# LCL clearly has higher Mean: 0.89 for LCL and 0.62 for HCL

##VISUALISATION
# boxplot 
bxp <- ggboxplot(
  EXP, x = "Condition", y = "Mean", palette = "jco")
bxp

#  plot
pl <- one_w_plot(EXP, emmean_dataframe, 'Condition', 'Mean', 'prob', 'Performance/Objective CF')
ggsave(pl, file=paste0(plotPrefix, "Acc_Cond_Plot.jpg"), width = 2500, height = 1500, dpi = 300, units = "px")
pl


####  DAY 1 vs DAY 2 #####
two_w <- glmer(Mean ~ Condition * Day + (1 | ID), weights = count,
   family = binomial, data = EXP)
emmeans1<- emmeans(two_w, pairwise ~ Condition * Day, adjust ="fdr", type = "response")
emmean_dataframe <- summary(emmeans1)$emmeans

Anova(two_w, type='III')
summary(emmeans1)
#summary  
sum <- sum_2 (EXP, 'Day', 'Condition', 'Mean')
sum

## VISUALISATION
# plot with error bars
pl <- plotty(EXP, emmean_dataframe, 'Day',  'Mean', 'Condition', 'prob', 'Perfromance/Objective CF') 
ggsave(pl, file=paste0(plotPrefix, "Acc_Cond_Day_Plot.jpg"), width = 2500, height = 1500, dpi = 300, units = "px")
pl

### Condition * Time * Day
three_w <- glmer(Mean ~ Condition * Time * Day + (1 | ID), weights = count,
   family = binomial, data = EXP)
emmeans1<- emmeans(three_w, pairwise ~ Condition * Time * Day, adjust ="fdr", type = "response")
emmean_dataframe <- summary(emmeans1)$emmeans
Anova(two_w, type='III')
summary(emmeans1)

## plot with error bars
max_y<-max(EXP$Mean)
pl <- plotty(EXP, emmean_dataframe, 'Time',  'Mean', 'Condition', 'prob', 'Performance/Objective CF') +
  facet_grid(.~Day)
  #   geom_segment(aes(x =0.9, y = max_y+max_y/15, xend = 1.1, yend = max_y+max_y/15), size= 1)+ # top line
  # annotate('text', x=1, y=max_y+max_y/15+max_y/100, label='**', size=7)+ # tar
  #   geom_segment(aes(x =1.9, y = max_y+max_y/15, xend = 2.1, yend = max_y+max_y/15), size= 1) # top line
  # # annotate('text', x=2, y=max_y+max_y/15+max_y/100, label='*', size=7) # star
ggsave(pl, file=paste0(plotPrefix, "Acc_Cond_Time_Plot.jpg"), width = 2500, height = 1500, dpi = 300, units = "px")
pl


### COMPONENTS (Color/Pic)####

# evolution over time for 2 components of the task
# Pics: decide if big/small. Color: decide if same as DualBack: more Working Memory
EXP1 <- as.data.frame (group_by(data, Condition, Day, Time, ID, Stim) %>%
  summarise(
    count = n(),
    Mean = mean(prop_correct, na.rm = TRUE)
  ))
# set factors
EXP1$Time <- as.factor(EXP1$Time)
EXP1$Condition <- as.factor(EXP1$Condition)
EXP1$Day <- as.factor(EXP1$Day)
EXP1$ID <- as.factor(EXP1$ID)
EXP1$Stim <- as.factor(EXP1$Stim)

## STATISTICAL TEST
three_w <- glmer(Mean ~ Condition * Time * Stim + (1 | ID), weights = count,
   family = binomial, data = EXP1)
emmeans1<- emmeans(three_w, pairwise ~ Condition * Time * Stim, adjust ="fdr", type = "response")
emmean_dataframe <- summary(emmeans1)$emmeans

Anova(three_w, type='III')
summary(emmeans1)

## plot with error bars
max_y<-max(EXP1$Mean)
pl <- plotty(EXP1, emmean_dataframe, 'Stim', 'Mean', 'Condition', 'prob', 'Accuracy') +
 facet_grid(.~Time)
  #   geom_segment(aes(x =0.9, y = max_y+max_y/15, xend = 1.1, yend = max_y+max_y/15), size= 1)+ # top line
  # annotate('text', x=1, y=max_y+max_y/15+max_y/100, label='**', size=7)+ # tar
  #   geom_segment(aes(x =1.9, y = max_y+max_y/15, xend = 2.1, yend = max_y+max_y/15), size= 1) # top line
  # # annotate('text', x=2, y=max_y+max_y/15+max_y/100, label='*', size=7) # star
ggsave(pl, file=paste0(plotPrefix, "EXP_Components_Plot.jpg"), width = 2500, height = 1500, dpi = 300, units = "px")
pl

two_w <- glmer(Mean ~ Time * Stim + (1 | ID), weights = count,
   family = binomial, data = EXP1)
emmeans1<- emmeans(two_w, pairwise ~ Time * Stim, adjust ="fdr", type = "response")
emmean_dataframe <- summary(emmeans1)$emmeans

Anova(three_w, type='III')
summary(emmeans1)

# summary
sum <- sum_2 (EXP1, 'Stim', 'Condition', 'Mean')
sum

pl <- plotti(EXP1, emmean_dataframe, 'Stim', 'Mean', 'Time', 'prob', 'Stimulus')


```


-----------------------------------------------------------------------------------

## CORRELATIONS

```{r message=FALSE, warning = FALSE}
##########################################
  ### CORRELATIONS ###
#########################################C

# Create 1 big dataframe
names(VAS)[names(VAS)=="Mean"] <- "VASf"
names(EXP)[names(EXP)=="Mean"] <- "Acc"
df <- merge(VAS, EXP, by = c('Day','Time', 'Condition', 'ID'))

length(unique(df$ID[df$Condition=='HCL']))
length(unique(df$ID[df$Condition=='LCL']))

### VAS-f ###

## CORR VAS-f Mean score between Day 1 and Day 2 (test-retest reliability)
# HCL 
Day1 <- VAS$VASf[VAS$Day==1 & VAS$Condition=='HCL']
Day2 <- VAS$VASf[VAS$Day==2 & VAS$Condition=='HCL']
VASfHCL <- corrplot(Day1, Day2, 'Day1', 'Day2') +ggtitle('VASf HCL')
#LCL
Day1 <- VAS$VASf[VAS$Day==1 & VAS$Condition=='LCL']
Day2 <- VAS$VASf[VAS$Day==2 & VAS$Condition=='LCL']
VASfLCL <- corrplot(Day1, Day2, 'Day1', 'Day2') +ggtitle('VASf LCL')
# cor.test(VAS$VASf[VAS$Condition=='HCL'], VAS$VASf[VAS$Condition=='LCL'],  method="spearman")# not Pearson because: not normal distribution
# cor.test(VAS$Mean[VAS$Condition=='HCL'], VAS$Mean[VAS$Condition=='LCL'],  method="kendall")

## CORR VAS-f delta between Day 1 and Day 2 
#HCL
Day1 <- VAS$VASf[VAS$Day==1 & VAS$Condition=='HCL' & VAS$Time==2]- VAS$VASf[VAS$Day==1 & VAS$Condition=='HCL' & VAS$Time==1]
Day2 <- VAS$VASf[VAS$Day==2 & VAS$Condition=='HCL' & VAS$Time==2]- VAS$VASf[VAS$Day==2 & VAS$Condition=='HCL' & VAS$Time==1]
VASf_delta_HCL <- corrplot(Day1, Day2, 'Day1', 'Day2') +ggtitle('VASf delta HCL')
#LCL
Day1 <- VAS$VASf[VAS$Day==1 & VAS$Condition=='LCL' & VAS$Time==2]- VAS$VASf[VAS$Day==1 & VAS$Condition=='LCL' & VAS$Time==1]
Day2 <- VAS$VASf[VAS$Day==2 & VAS$Condition=='LCL' & VAS$Time==2]- VAS$VASf[VAS$Day==2 & VAS$Condition=='LCL' & VAS$Time==1]
VASf_delta_LCL <- corrplot(Day1, Day2, 'Day1', 'Day2') +ggtitle('VASf delta LCL')

VASfCORR <- ggarrange(VASfHCL, VASfLCL, VASf_delta_HCL, VASf_delta_LCL + rremove("x.text"), 
          labels = c("A", "B", "C", "D"),
          ncol = 2, nrow = 2)
ggsave(VASfCORR, file=paste0(plotPrefix, "VASf_CORR.jpg"), width = 2500, height = 1500, dpi = 300, units = "px")
VASfCORR

### Accuracy ###

## CORR Accuracy Day 1 and Day 2  (test-retest reliability)
#HCL
Day1 <- EXP$Acc[EXP$Day==1 & EXP$Condition=='HCL' & EXP$Time==2]- EXP$Acc[EXP$Day==1 & EXP$Condition=='HCL' & EXP$Time==1]
Day2 <- EXP$Acc[EXP$Day==2 & EXP$Condition=='HCL' & EXP$Time==2]- EXP$Acc[EXP$Day==2 & EXP$Condition=='HCL' & EXP$Time==1]
EXPHCL<-corrplot(Day1, Day2, 'Day1', 'Day2') +ggtitle('Performance HCL')
#LCL
Day1 <- EXP$Acc[EXP$Day==1 & EXP$Condition=='LCL' & EXP$Time==2]- EXP$Acc[EXP$Day==1 & EXP$Condition=='LCL' & EXP$Time==1]
Day2 <- EXP$Acc[EXP$Day==2 & EXP$Condition=='LCL' & EXP$Time==2]- EXP$Acc[EXP$Day==2 & EXP$Condition=='LCL' & EXP$Time==1]
EXPLCL<-corrplot(Day1, Day2, 'Day1', 'Day2') +ggtitle('Performance LCL')

## CORR Accuracy delta between Day 1 and Day 2 
#HCL
Day1 <- EXP$Acc[EXP$Day==1 & EXP$Condition=='HCL' & EXP$Time==2]- EXP$Acc[EXP$Day==1 & EXP$Condition=='HCL' & EXP$Time==1]
Day2 <- EXP$Acc[EXP$Day==2 & EXP$Condition=='HCL' & EXP$Time==2]- EXP$Acc[EXP$Day==2 & EXP$Condition=='HCL' & EXP$Time==1]
EXP_DELTA_HCL<- corrplot(Day1, Day2, 'Day1', 'Day2') +ggtitle('Performance delta HCL') # negative correlation: when high in day 1, low in day 2
#LCL
Day1 <- EXP$Acc[EXP$Day==1 & EXP$Condition=='LCL' & EXP$Time==2]- EXP$Acc[EXP$Day==1 & EXP$Condition=='LCL' & EXP$Time==1]
Day2 <- EXP$Acc[EXP$Day==2 & EXP$Condition=='LCL' & EXP$Time==2]- EXP$Acc[EXP$Day==2 & EXP$Condition=='LCL' & EXP$Time==1]
EXP_DELTA_LCL<-corrplot(Day1, Day2, 'Day1', 'Day2') +ggtitle('Performance delta LCL') # positive correlation: when high in day 1, high in day 2

EXPCORR <- ggarrange(EXPHCL, EXPLCL, EXP_DELTA_HCL, EXP_DELTA_LCL + rremove("x.text"), 
          labels = c("A", "B", "C", "D"),
          ncol = 2, nrow = 2)
ggsave(EXPCORR, file=paste0(plotPrefix, "EXP_CORR.jpg"), width = 2500, height = 1500, dpi = 300, units = "px")
EXPCORR


### VAS-f * Acc ###
## CORR delta (change) VAS-f and delta Acc
#HCL
VAS_f <- df$VASf[df$Time==2 & df$Condition=='HCL'] - df$VASf[df$Time==1 & df$Condition=='HCL']
ACC<- df$Acc[df$Time==2 & df$Condition=='HCL'] - df$Acc[df$Time==1 & df$Condition=='HCL']
DELTAHCL<- corrplot(VAS_f, ACC, 'VASf delta', 'Performance delta') +ggtitle('delta correlations HCL') # no correlation: change before-after test in VASf no correlation with obj CF changes 
#LCL
VAS_f <- df$VASf[df$Time==2 & df$Condition=='LCL'] - df$VASf[df$Time==1 & df$Condition=='LCL']
ACC<- df$Acc[df$Time==2 & df$Condition=='LCL'] - df$Acc[df$Time==1 & df$Condition=='LCL']
DELTALCL<- corrplot(VAS_f, ACC, 'VASf delta', 'Performance delta') +ggtitle('delta correlations LCL') 

DELTACORR<- ggarrange (DELTAHCL, DELTALCL+ rremove('x.text'), labels= c('A', 'B'))
ggsave(DELTACORR, file=paste0(plotPrefix, "DELAT_CORR.jpg"), width = 2500, height = 1500, dpi = 300, units = "px")
DELTACORR

```


